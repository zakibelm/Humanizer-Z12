
import { GoogleGenAI, Type } from "@google/genai";
import { StyleCategory, StyleDistribution, AnalysisResult, StylometricProfile } from '../types';
import { analyzeText, compareProfiles, createCompositeProfile } from './stylometryService';

export interface GenerationOutput {
    text: string;
    analysis: AnalysisResult;
}

const constructPrompt = (topic: string, styles: StyleCategory[], distribution: StyleDistribution, targetProfile?: StylometricProfile): string => {
  let prompt = `
**CONTEXTE:** Tu es un ma√Ætre r√©dacteur, Humanizer Z12. Ta mission est de g√©n√©rer un texte sur un sujet donn√© qui √©chappe √† la d√©tection par les outils d'IA (comme ZeroGPT). Pour ce faire, tu dois imiter les imperfections et les variations du style d'√©criture humain en te basant sur une biblioth√®que de styles fournie.

**TA BIBLIOTH√àQUE D'INSPIRATION :**
Voici les styles que tu dois m√©langer de mani√®re organique.

`;

  styles.forEach(category => {
    if (category.documents.length > 0) {
      prompt += `
---
**STYLE : ${category.name} (INFLUENCE GUIDANTE : ${distribution[category.id]}%)**
${category.documents.map(doc => `[EXTRAIT]${doc.content}[/EXTRAIT]`).join('\n')}
---
`;
    }
  });

  // Ajouter contraintes stylom√©triques si disponibles
  if (targetProfile) {
    prompt += `
**CONTRAINTES STYLOM√âTRIQUES STRICTES (RESPECTE CES M√âTRIQUES) :**
Tu DOIS g√©n√©rer un texte qui correspond aux param√®tres statistiques suivants :

üìä **STRUCTURE DES PHRASES :**
- Longueur moyenne : ${targetProfile.sentenceStats.mean.toFixed(1)} mots par phrase
- Variation (√©cart-type) : ${targetProfile.sentenceStats.stdDev.toFixed(1)} (CRUCIAL : varie beaucoup les longueurs)
- Phrases courtes (<10 mots) : ${targetProfile.sentenceStats.shortSentences.toFixed(0)}% du total
- Phrases longues (>25 mots) : ${targetProfile.sentenceStats.longSentences.toFixed(0)}% du total
- Plage : entre ${targetProfile.sentenceStats.min} et ${targetProfile.sentenceStats.max} mots

üìö **RICHESSE LEXICALE :**
- Diversit√© vocabulaire (TTR) : ${targetProfile.typeTokenRatio.toFixed(2)} (ne r√©p√®te pas trop les mots)
- Mots uniques : ${(targetProfile.hapaxLegomenaRatio * 100).toFixed(0)}% du vocabulaire utilis√© une seule fois
- Longueur moyenne des mots : ${targetProfile.averageWordLength.toFixed(1)} lettres

‚úçÔ∏è **PONCTUATION :**
- Virgules : ~${targetProfile.punctuationProfile.commaRatio.toFixed(1)} par 100 mots
- Points-virgules : ~${targetProfile.punctuationProfile.semicolonRatio.toFixed(1)} par 100 mots
- Tirets/traits d'union : ~${targetProfile.punctuationProfile.dashRatio.toFixed(1)} par 100 mots
- Questions : ${targetProfile.punctuationProfile.questionRatio.toFixed(1)}% des phrases
- Exclamations : ${targetProfile.punctuationProfile.exclamationRatio.toFixed(1)}% des phrases

üó£Ô∏è **PATTERNS LINGUISTIQUES :**
- Contractions (c'est, j'ai, etc.) : ${targetProfile.patterns.contractionRatio.toFixed(1)}% des mots
- Phrases commen√ßant par conjonction (Et, Mais...) : ${targetProfile.patterns.startWithConjunction.toFixed(0)}%
- Lisibilit√© (Flesch) : ${targetProfile.readability.fleschScore.toFixed(0)}/100

`;
  }

  prompt += `
**INSTRUCTIONS CRITIQUES :**

1.  **G√âN√àRE LE TEXTE :** R√©dige un texte sur le sujet : "${topic}".

2.  **TECHNIQUES OBLIGATOIRES POUR HUMANISATION :**

    a) **VARIATION EXTR√äME DES PHRASES :**
       - Alterne phrases ultra-courtes (3-7 mots) et phrases complexes (25-40 mots)
       - Exemple : "C'est simple. Mais quand on creuse et qu'on analyse les donn√©es de pr√®s, en tenant compte des multiples variables contextuelles et des nuances qui √©chappent souvent √† une premi√®re lecture superficielle, la r√©alit√© s'av√®re bien plus complexe."

    b) **IMPERFECTIONS NATURELLES :**
       - Inclus 1-2 phrases l√©g√®rement maladroites ou redondantes (comme si tu h√©sites)
       - Reformule une m√™me id√©e sous deux angles diff√©rents
       - Ajoute des transitions parfois abruptes entre paragraphes
       - Une phrase peut occasionnellement √™tre l√©g√®rement bancale grammaticalement (sans √™tre incorrecte)

    c) **LANGAGE AUTHENTIQUE :**
       - Utilise des contractions informelles : "c'est", "j'ai", "l'on", "qu'on"
       - Int√®gre expressions famili√®res : "en gros", "du coup", "en fait", "plut√¥t", "assez"
       - Pose 1-2 questions rh√©toriques au lecteur
       - Utilise "Et" ou "Mais" pour d√©buter certaines phrases (10-15%)

    d) **PONCTUATION VARI√âE :**
       - Utilise des tirets ‚Äî pour les apart√©s
       - Quelques points-virgules pour relier des id√©es
       - Une ou deux phrases avec points de suspension... (h√©sitation)

    e) **VOCABULAIRE HUMAIN :**
       - M√©lange registres formel/informel dans le m√™me texte
       - Utilise des m√©taphores quotidiennes
       - √âvite les formulations trop "parfaites" ou acad√©miques syst√©matiques
       - Ins√®re des mots de liaison naturels ("d'ailleurs", "en revanche", "cela dit")

3.  **AUTO-ANALYSE DE RISQUE (JSON OBLIGATOIRE) :** Apr√®s la r√©daction, fournis une analyse de risque de d√©tection dans un objet JSON. Ne m√©lange jamais l'analyse avec le texte.
    *   \`detectionRisk\`: Un objet √©valuant le risque global.
        *   \`score\`: Un score num√©rique de 0 √† 100 indiquant la probabilit√© que le texte soit per√ßu comme humain (100 = tr√®s humain).
        *   \`level\`: Le niveau de risque correspondant ('Faible' pour score > 70, 'Mod√©r√©' pour 40-70, '√âlev√©' pour < 40).
    *   \`perplexity\`: Un objet analysant la pr√©visibilit√© du texte.
        *   \`score\`: Un score num√©rique de 0 √† 100 (100 = tr√®s impr√©visible, donc plus humain).
        *   \`analysis\`: Explique bri√®vement l'impact du score.
    *   \`burstiness\`: Un objet analysant la variation des phrases.
        *   \`score\`: Un score de 0 √† 100 (100 = grande variation de longueur/structure, donc plus humain).
        *   \`analysis\`: Explique bri√®vement l'impact du score.
    *   \`flaggedSentences\`: Un tableau listant les 1 √† 3 phrases EXACTES du texte qui sont les plus susceptibles d'√™tre d√©tect√©es.

**IMPORTANT :** Ne sois PAS parfait. Un vrai humain fait des choix stylistiques discutables, se r√©p√®te parfois, et n'optimise pas chaque phrase. C'est cette imperfection qui rend le texte authentique.

**TA T√ÇCHE :**
G√©n√®re le texte sur "${topic}", puis fournis l'analyse JSON s√©par√©e.
`;

  return prompt;
};

const constructRefinePrompt = (textToRefine: string, flaggedSentences: string[]): string => {
    return `
**CONTEXTE:** Tu es un expert en r√©vision, Humanizer Z12. Ta mission est d'am√©liorer un texte existant pour qu'il paraisse encore plus humain et √©chappe √† la d√©tection par IA.

**TEXTE √Ä AM√âLIORER:**
"${textToRefine}"

**POINTS FAIBLES IDENTIFI√âS (PHRASES √Ä RISQUE):**
${flaggedSentences.map(s => `- "${s}"`).join('\n')}

**INSTRUCTIONS CRITIQUES:**
1.  **R√â√âCRIS LE TEXTE :** Modifie le texte fourni pour augmenter sa "Perplexit√©" (le rendre moins pr√©visible) et sa "Variation" (varier davantage la longueur et la structure des phrases).
2.  **CIBLE LES POINTS FAIBLES :** Concentre tes efforts sur la r√©√©criture des "phrases √† risque" identifi√©es. Remplace-les par des alternatives plus naturelles et moins g√©n√©riques.
3.  **CONSERVE LE SENS :** Ne modifie pas le message ou les informations cl√©s du texte original. L'objectif est de changer le style, pas le fond.
4.  **FOURNIS UNE NOUVELLE ANALYSE (JSON OBLIGATOIRE) :** Apr√®s avoir am√©lior√© le texte, fournis une nouvelle analyse de risque compl√®te et chiffr√©e, en visant des scores plus √©lev√©s. Le format JSON doit √™tre identique √† celui de la g√©n√©ration initiale (detectionRisk, perplexity, burstiness, flaggedSentences).

**TA T√ÇCHE :**
Produis le texte am√©lior√©, puis fournis la nouvelle analyse JSON.
`;
}

const responseSchema = {
    type: Type.OBJECT,
    properties: {
        humanizedText: {
            type: Type.STRING,
            description: "Le texte final g√©n√©r√© qui imite l'√©criture humaine.",
        },
        analysis: {
            type: Type.OBJECT,
            description: "Une auto-analyse de risque du texte g√©n√©r√©.",
            properties: {
                detectionRisk: {
                    type: Type.OBJECT,
                    properties: {
                        level: { type: Type.STRING, description: "Niveau de risque (Faible, Mod√©r√©, √âlev√©)." },
                        score: { type: Type.INTEGER, description: "Score de probabilit√© humaine (0-100)." },
                    },
                    required: ["level", "score"]
                },
                perplexity: {
                    type: Type.OBJECT,
                    properties: {
                        score: { type: Type.INTEGER, description: "Score de perplexit√© (0-100)." },
                        analysis: { type: Type.STRING, description: "Analyse de la perplexit√©/pr√©visibilit√©." }
                    },
                    required: ["score", "analysis"]
                },
                burstiness: {
                    type: Type.OBJECT,
                    properties: {
                        score: { type: Type.INTEGER, description: "Score de variation (0-100)." },
                        analysis: { type: Type.STRING, description: "Analyse de la variation/rafale." }
                    },
                     required: ["score", "analysis"]
                },
                flaggedSentences: {
                    type: Type.ARRAY,
                    items: { type: Type.STRING },
                    description: "Phrases les plus susceptibles d'√™tre d√©tect√©es."
                }
            },
            required: ["detectionRisk", "perplexity", "burstiness", "flaggedSentences"],
        },
    },
    required: ["humanizedText", "analysis"],
};


const defaultErrorAnalysis: AnalysisResult = {
    detectionRisk: {
        level: "√âlev√©",
        score: 0,
    },
    perplexity: {
        score: 0,
        analysis: "Impossible d'analyser la perplexit√©.",
    },
    burstiness: {
        score: 0,
        analysis: "Impossible d'analyser la variation.",
    },
    flaggedSentences: ["Impossible de r√©cup√©rer les phrases √† risque."],
};

const callGemini = async (prompt: string, targetProfile?: StylometricProfile): Promise<GenerationOutput> => {
    try {
        const ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });

        const response = await ai.models.generateContent({
          model: 'gemini-2.5-pro',
          contents: prompt,
          config: {
            responseMimeType: "application/json",
            responseSchema,
            temperature: 1.2,        // ‚úÖ Augmente l'impr√©visibilit√©
            topP: 0.95,             // ‚úÖ Diversit√© lexicale
            topK: 50,               // ‚úÖ Vari√©t√© des choix de mots
          }
        });

        const jsonResponse = JSON.parse(response.text);

        // Analyse stylom√©trique du texte g√©n√©r√©
        let stylometricMatch = undefined;
        if (targetProfile && jsonResponse.humanizedText) {
            const generatedProfile = analyzeText(jsonResponse.humanizedText);
            const comparison = compareProfiles(targetProfile, generatedProfile);

            stylometricMatch = {
                similarity: comparison.similarity,
                deviations: comparison.deviations
                    .filter(d => d.severity === 'high' || d.severity === 'medium')
                    .map(d => `${d.metric}: ${d.deviation.toFixed(0)}% d'√©cart`),
            };
        }

        return {
            text: jsonResponse.humanizedText,
            analysis: {
                ...jsonResponse.analysis,
                stylometricMatch,
            },
        };

    } catch (error) {
        console.error("Error calling Gemini:", error);
        if (error instanceof Error) {
            return { text: `Une erreur est survenue : ${error.message}`, analysis: defaultErrorAnalysis };
        }
        return { text: "Une erreur inconnue est survenue.", analysis: defaultErrorAnalysis };
    }
}


export const generateHumanizedText = async (
  topic: string,
  styles: StyleCategory[],
  distribution: StyleDistribution
): Promise<GenerationOutput> => {
  // Calculer le profil stylom√©trique composite des documents de r√©f√©rence
  const allDocumentTexts: string[] = [];
  styles.forEach(category => {
    const weight = distribution[category.id] / 100;
    category.documents.forEach(doc => {
      // Ajouter proportionnellement au poids de distribution
      const repetitions = Math.max(1, Math.round(weight * 3));
      for (let i = 0; i < repetitions; i++) {
        allDocumentTexts.push(doc.content);
      }
    });
  });

  const targetProfile = allDocumentTexts.length > 0
    ? createCompositeProfile(allDocumentTexts)
    : undefined;

  const fullPrompt = constructPrompt(topic, styles, distribution, targetProfile);
  return callGemini(fullPrompt, targetProfile);
};

export const refineHumanizedText = async (
    textToRefine: string,
    flaggedSentences: string[]
): Promise<GenerationOutput> => {
    const refinePrompt = constructRefinePrompt(textToRefine, flaggedSentences);
    return callGemini(refinePrompt);
}

/**
 * Analyse un texte existant sans le modifier
 * Retourne seulement l'analyse de risque
 */
export const analyzeExistingText = async (
    text: string,
    targetProfile?: StylometricProfile
): Promise<GenerationOutput> => {
    const analyzePrompt = `
**CONTEXTE:** Tu es un expert en analyse de texte, Humanizer Z12. Ta mission est d'analyser un texte existant pour d√©terminer s'il peut √™tre d√©tect√© comme g√©n√©r√© par IA.

**TEXTE √Ä ANALYSER:**
"${text}"

**INSTRUCTIONS:**
1. NE MODIFIE PAS le texte fourni
2. Retourne le texte EXACTEMENT tel quel dans le champ "humanizedText"
3. Fournis une analyse compl√®te de risque de d√©tection (JSON)

**ANALYSE REQUISE (JSON OBLIGATOIRE):**
*   \`detectionRisk\`: Un objet √©valuant le risque global.
    *   \`score\`: Un score num√©rique de 0 √† 100 indiquant la probabilit√© que le texte soit per√ßu comme humain (100 = tr√®s humain).
    *   \`level\`: Le niveau de risque correspondant ('Faible' pour score > 70, 'Mod√©r√©' pour 40-70, '√âlev√©' pour < 40).
*   \`perplexity\`: Un objet analysant la pr√©visibilit√© du texte.
    *   \`score\`: Un score num√©rique de 0 √† 100 (100 = tr√®s impr√©visible, donc plus humain).
    *   \`analysis\`: Explique bri√®vement l'impact du score.
*   \`burstiness\`: Un objet analysant la variation des phrases.
    *   \`score\`: Un score de 0 √† 100 (100 = grande variation de longueur/structure, donc plus humain).
    *   \`analysis\`: Explique bri√®vement l'impact du score.
*   \`flaggedSentences\`: Un tableau listant les 1 √† 3 phrases EXACTES du texte qui sont les plus susceptibles d'√™tre d√©tect√©es comme IA.

**TA T√ÇCHE:**
Retourne le texte INCHANG√â et fournis l'analyse JSON.
`;

    return callGemini(analyzePrompt, targetProfile);
}
